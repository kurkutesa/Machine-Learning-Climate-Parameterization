{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries, set random seed, define rainy threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:20:34.168374Z",
     "start_time": "2019-02-14T01:20:30.557537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages imported.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import floor, ceil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import xarray as xr\n",
    "import tensorflow as tf\n",
    "\n",
    "print('All packages imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:20:34.174451Z",
     "start_time": "2019-02-14T01:20:34.170676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42.\n"
     ]
    }
   ],
   "source": [
    "# Random seed for reproducibility\n",
    "\n",
    "seed = 42\n",
    "print(f'Random seed set as {seed}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:20:34.181742Z",
     "start_time": "2019-02-14T01:20:34.177305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold of rainy event is 0 mm/hr\n",
      "Classification\n"
     ]
    }
   ],
   "source": [
    "# Set threshold of rainy events\n",
    "classification = True\n",
    "\n",
    "prec_threshold = 0\n",
    "print(f'Threshold of rainy event is {prec_threshold} mm/hr')\n",
    "print('Classification' if classification else 'Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:20:34.188884Z",
     "start_time": "2019-02-14T01:20:34.184667Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_file_path(file_name):\n",
    "    CURRENT_DIR = os.getcwd()\n",
    "    DATA_DIR = f'{CURRENT_DIR}/../../../data/stage-1_cleaned'\n",
    "    FILE_PATH = f'{DATA_DIR}/{file_name}'\n",
    "    return FILE_PATH\n",
    "\n",
    "\n",
    "def import_DS(FILE_PATH):\n",
    "    return xr.open_dataset(FILE_PATH)\n",
    "\n",
    "def DS_dropna(DS):\n",
    "    return DS.dropna(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:20:34.249954Z",
     "start_time": "2019-02-14T01:20:34.190742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:                    (p: 37, time: 4759)\n",
       "Coordinates:\n",
       "  * time                       (time) datetime64[ns] 1997-08-28T04:30:00 ... 2010-08-25T23:30:00\n",
       "  * p                          (p) float32 1000.0 975.0 950.0 ... 125.0 100.0\n",
       "Data variables:\n",
       "    prec_sfc_next              (time) float32 ...\n",
       "    T_sfc                      (time) float32 ...\n",
       "    p_sfc                      (time) float32 ...\n",
       "    rh_sfc                     (time) float32 ...\n",
       "    u_sfc                      (time) float32 ...\n",
       "    v_sfc                      (time) float32 ...\n",
       "    prec_sfc                   (time) float32 ...\n",
       "    T_p                        (time, p) float32 ...\n",
       "    rh_p                       (time, p) float32 ...\n",
       "    u_p                        (time, p) float32 ...\n",
       "    v_p                        (time, p) float32 ...\n",
       "    down_short_diffuse_hemisp  (time) float64 ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE_PATH = get_file_path(file_name='merged_dropped.cdf')\n",
    "DS_raw = import_DS(FILE_PATH)\n",
    "DS_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:20:34.283495Z",
     "start_time": "2019-02-14T01:20:34.251975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:                    (p: 37, time: 4759)\n",
       "Coordinates:\n",
       "  * time                       (time) datetime64[ns] 1997-08-28T04:30:00 ... 2010-08-25T23:30:00\n",
       "  * p                          (p) float32 1000.0 975.0 950.0 ... 125.0 100.0\n",
       "Data variables:\n",
       "    prec_sfc_next              (time) float32 0.04966664 0.04999997 ... 0.0 0.0\n",
       "    T_sfc                      (time) float32 300.92734 301.03537 ... 299.10202\n",
       "    p_sfc                      (time) float32 1008.7901 ... 1010.95233\n",
       "    rh_sfc                     (time) float32 80.57 72.501755 ... 87.67273\n",
       "    u_sfc                      (time) float32 -2.7884665 ... -1.1461726\n",
       "    v_sfc                      (time) float32 4.551383 5.972651 ... 2.0953407\n",
       "    prec_sfc                   (time) float32 0.047666643 ... 0.44877273\n",
       "    T_p                        (time, p) float32 299.9794 297.85 ... 195.81091\n",
       "    rh_p                       (time, p) float32 72.117645 ... 21.037518\n",
       "    u_p                        (time, p) float32 -2.8401828 ... -8.03497\n",
       "    v_p                        (time, p) float32 4.7782855 ... 2.6448529\n",
       "    down_short_diffuse_hemisp  (time) float64 191.3 210.8 ... -0.2421 175.1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS = DS_dropna(DS_raw)\n",
    "DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:20:34.293590Z",
     "start_time": "2019-02-14T01:20:34.285474Z"
    }
   },
   "outputs": [],
   "source": [
    "str_y = 'prec_sfc_next'\n",
    "str_x_scalar = ['T_sfc', 'p_sfc', 'rh_sfc', 'u_sfc', 'v_sfc', 'prec_sfc', 'down_short_diffuse_hemisp']\n",
    "str_x_1d = ['T_p', 'rh_p', 'u_p', 'v_p']\n",
    "plev = DS['p'].values.astype(float)  # array of pressure level\n",
    "\n",
    "def extract(DS, str_y=str_y, str_x_scalar=str_x_scalar):\n",
    "    return DS[str_y].to_dataframe().values, DS[str_x_scalar].to_dataframe().values\n",
    "\n",
    "\n",
    "def merge_channels(DS, str_x_1d=str_x_1d):\n",
    "    channels = [DS[str_x_1d[i]].to_dataframe().unstack(level=-1)\n",
    "                for i in range(0, len(str_x_1d))]\n",
    "    X_conv = np.expand_dims(channels[0].values, axis=2)\n",
    "\n",
    "    for channel in channels[1:]:\n",
    "        channel = np.expand_dims(channel.values, axis=2)\n",
    "        X_conv = np.append(X_conv, channel, axis=2)\n",
    "\n",
    "    return X_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:20:34.302659Z",
     "start_time": "2019-02-14T01:20:34.295410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4759, 1)\n",
      "(4759, 7)\n"
     ]
    }
   ],
   "source": [
    "y, X_scalar = extract(DS)\n",
    "print(y.shape)\n",
    "print(X_scalar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:20:34.455004Z",
     "start_time": "2019-02-14T01:20:34.304748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4759, 37, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_conv = merge_channels(DS)\n",
    "X_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:20:34.460649Z",
     "start_time": "2019-02-14T01:20:34.456935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 class ratio= 48.60%\n"
     ]
    }
   ],
   "source": [
    "binary = y > prec_threshold\n",
    "print('1 class ratio= {:.2%}'.format(binary.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:20:34.477817Z",
     "start_time": "2019-02-14T01:20:34.464456Z"
    }
   },
   "outputs": [],
   "source": [
    "def split(binary, y, X_scalar, X_conv, train_size=0.75, seed=seed):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_binary, test_binary, train_y, test_y, train_X_scalar, test_X_scalar, train_X_conv, test_X_conv = train_test_split(binary, y, X_scalar, X_conv,\n",
    "                                                                                                                            train_size=train_size,\n",
    "                                                                                                                            random_state=seed,\n",
    "                                                                                                                            shuffle=True,\n",
    "                                                                                                                            stratify=None)\n",
    "    return train_binary, test_binary, train_y, test_y, train_X_scalar, test_X_scalar, train_X_conv, test_X_conv\n",
    "\n",
    "\n",
    "def standardize(train, test):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    train = scaler.fit_transform(train)\n",
    "    test = scaler.transform(test)\n",
    "    return train, test, scaler\n",
    "\n",
    "\n",
    "def standardize_3d(train, test):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scalers = {}\n",
    "    for i in range(train.shape[2]):\n",
    "        scalers[i] = StandardScaler()\n",
    "        train[:, :, i] = scalers[i].fit_transform(train[:, :, i])\n",
    "\n",
    "    for i in range(test.shape[2]):\n",
    "        test[:, :, i] = scalers[i].transform(test[:, :, i])\n",
    "\n",
    "    return train, test, scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:20:34.569192Z",
     "start_time": "2019-02-14T01:20:34.479642Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/s1895566/miniconda/base/envs/venv/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# train-test split\n",
    "train_binary, test_binary, train_y, test_y, train_X_scalar, test_X_scalar, train_X_conv, test_X_conv = split(\n",
    "    binary, y, X_scalar, X_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:20:34.605692Z",
     "start_time": "2019-02-14T01:20:34.571342Z"
    }
   },
   "outputs": [],
   "source": [
    "# standardize\n",
    "train_y, test_y, scaler_y = standardize(train_y, test_y)\n",
    "train_X_scalar, test_X_scalar, scaler_X_scalar = standardize(train_X_scalar, test_X_scalar)\n",
    "train_X_conv, test_X_conv, scalers_X_conv = standardize_3d(train_X_conv, test_X_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:20:34.613518Z",
     "start_time": "2019-02-14T01:20:34.608972Z"
    }
   },
   "outputs": [],
   "source": [
    "def flattening_merge(_3d, _2d):\n",
    "    flat = _2d\n",
    "    for i in range(0,_3d.shape[2]):\n",
    "        flat = np.concatenate((flat, _3d[:,:,i]), axis=1)\n",
    "    return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:20:34.628198Z",
     "start_time": "2019-02-14T01:20:34.615540Z"
    }
   },
   "outputs": [],
   "source": [
    "train_X = flattening_merge(train_X_conv, train_X_scalar)\n",
    "test_X = flattening_merge(test_X_conv, test_X_scalar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:20:34.636322Z",
     "start_time": "2019-02-14T01:20:34.630369Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "all_data = (train_X, test_X, train_binary[:,0], test_binary[:,0]) if classification else (train_X, test_X, train_y[:,0], test_y[:,0])\n",
    "\n",
    "\n",
    "def all_x(data):\n",
    "    train_X, test_X, train_y, test_y = data\n",
    "    return np.concatenate((train_X, test_X))\n",
    "\n",
    "\n",
    "def all_y(data):\n",
    "    train_X, test_X, train_y, test_y = data\n",
    "    return np.concatenate((train_y, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:20:34.653149Z",
     "start_time": "2019-02-14T01:20:34.642395Z"
    }
   },
   "outputs": [],
   "source": [
    "def KNN(data, n_neighbors, mode='cv', n_folds=5):\n",
    "    train_x, test_x, train_y, test_y = data\n",
    "\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "\n",
    "    if mode == 'cv':\n",
    "        acc_list = cross_val_score(knn, all_x(data), all_y(data),\n",
    "                                   cv=n_folds,\n",
    "                                   n_jobs=-1)\n",
    "        return None, acc_list\n",
    "    else:\n",
    "        knn = knn.fit(train_x, train_y)\n",
    "        test_y_hat = knn.predict(test_x)\n",
    "        acc = accuracy_score(test_y_hat, test_y)\n",
    "\n",
    "        print(classification_report(test_y, test_y_hat))\n",
    "        print(confusion_matrix(test_y, test_y_hat))\n",
    "        return knn, acc\n",
    "\n",
    "\n",
    "def KNN_grid_search(data, n_neighbors_grid=range(1, 11)):\n",
    "    n_neighbors_opt, acc_opt = 0, 0\n",
    "    for k in n_neighbors_grid:\n",
    "        _, acc_list = KNN(data,\n",
    "                          n_neighbors=k,\n",
    "                          mode='cv')\n",
    "        acc_mean, acc_std = acc_list.mean(), acc_list.std()\n",
    "        print(f'KNN k={k}: CV Accuracy= [{acc_mean:.4f}] + [{acc_std:.4f}]')\n",
    "        if acc_mean > acc_opt:\n",
    "            n_neighbors_opt, acc_opt = k, acc_mean\n",
    "\n",
    "    knn, acc = KNN(data,\n",
    "                   n_neighbors=n_neighbors_opt,\n",
    "                   mode='train')\n",
    "    print(f'\\nKNN k={n_neighbors_opt}: Accuracy= {acc:.4f}')\n",
    "    return knn, acc_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:20:59.783583Z",
     "start_time": "2019-02-14T01:20:34.658840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN k=1: CV Accuracy= [0.6115] + [0.0128]\n",
      "KNN k=2: CV Accuracy= [0.6056] + [0.0098]\n",
      "KNN k=3: CV Accuracy= [0.6167] + [0.0072]\n",
      "KNN k=4: CV Accuracy= [0.6155] + [0.0099]\n",
      "KNN k=5: CV Accuracy= [0.6190] + [0.0132]\n",
      "KNN k=6: CV Accuracy= [0.6085] + [0.0133]\n",
      "KNN k=7: CV Accuracy= [0.6237] + [0.0144]\n",
      "KNN k=8: CV Accuracy= [0.6171] + [0.0152]\n",
      "KNN k=9: CV Accuracy= [0.6249] + [0.0115]\n",
      "KNN k=10: CV Accuracy= [0.6222] + [0.0081]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.66      0.63      0.64       625\n",
      "       True       0.61      0.64      0.62       565\n",
      "\n",
      "avg / total       0.63      0.63      0.63      1190\n",
      "\n",
      "[[393 232]\n",
      " [204 361]]\n",
      "\n",
      "KNN k=9: Accuracy= 0.6336\n"
     ]
    }
   ],
   "source": [
    "# 1. KNN\n",
    "knn, knn_cv_acc = KNN_grid_search(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T00:11:43.121409Z",
     "start_time": "2019-02-14T00:11:43.118633Z"
    }
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:20:59.804100Z",
     "start_time": "2019-02-14T01:20:59.787927Z"
    }
   },
   "outputs": [],
   "source": [
    "def LogReg(data, penalty, beta, mode='cv', n_folds=5, seed=seed):\n",
    "    train_x, test_x, train_y, test_y = data\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    logreg = LogisticRegression(penalty=penalty,\n",
    "                                C=beta,\n",
    "                                max_iter=1000)\n",
    "\n",
    "    if mode == 'cv':\n",
    "        acc_list = cross_val_score(logreg, all_x(data), all_y(data),\n",
    "                                   cv=n_folds,\n",
    "                                   n_jobs=-1)\n",
    "        return None, acc_list\n",
    "    else:\n",
    "        logreg = logreg.fit(train_x, train_y)\n",
    "        test_y_hat = logreg.predict(test_x)\n",
    "        acc = accuracy_score(test_y_hat, test_y)\n",
    "\n",
    "        print(classification_report(test_y, test_y_hat))\n",
    "        print(confusion_matrix(test_y, test_y_hat))\n",
    "        return logreg, acc\n",
    "\n",
    "\n",
    "beta_grid = np.concatenate((np.linspace(.1, .9, 9), np.linspace(1, 10, 10)))\n",
    "\n",
    "\n",
    "def LogReg_grid_search(data, penalty_grid=['l2', 'l1'], beta_grid=beta_grid):\n",
    "    penalty_opt, beta_opt, acc_opt = '', 0, 0\n",
    "    for penalty in penalty_grid:\n",
    "        for beta in beta_grid:\n",
    "            _, acc_list = LogReg(data,\n",
    "                                 penalty=penalty,\n",
    "                                 beta=beta,\n",
    "                                 mode='cv')\n",
    "            acc_mean, acc_std = acc_list.mean(), acc_list.std()\n",
    "            print(\n",
    "                f'{penalty.capitalize()} LogReg β={beta:.1f}: CV Accuracy= [{acc_mean:.4f}] + [{acc_std:.4f}]')\n",
    "            if acc_mean > acc_opt:\n",
    "                penalty_opt, beta_opt, acc_opt = penalty, beta, acc_mean\n",
    "\n",
    "    logreg, acc = LogReg(data,\n",
    "                         penalty=penalty_opt,\n",
    "                         beta=beta_opt,\n",
    "                         mode='train')\n",
    "    print(\n",
    "        f'\\n{penalty_opt.capitalize()} LogReg β={beta_opt:.1f}: Accuracy= {acc:.4f}')\n",
    "    return logreg, acc_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:22:24.291087Z",
     "start_time": "2019-02-14T01:20:59.806205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 LogReg β=0.1: CV Accuracy= [0.7041] + [0.0088]\n",
      "L2 LogReg β=0.2: CV Accuracy= [0.7043] + [0.0087]\n",
      "L2 LogReg β=0.3: CV Accuracy= [0.7050] + [0.0064]\n",
      "L2 LogReg β=0.4: CV Accuracy= [0.7029] + [0.0068]\n",
      "L2 LogReg β=0.5: CV Accuracy= [0.7025] + [0.0085]\n",
      "L2 LogReg β=0.6: CV Accuracy= [0.7025] + [0.0096]\n",
      "L2 LogReg β=0.7: CV Accuracy= [0.7018] + [0.0098]\n",
      "L2 LogReg β=0.8: CV Accuracy= [0.7016] + [0.0106]\n",
      "L2 LogReg β=0.9: CV Accuracy= [0.7016] + [0.0109]\n",
      "L2 LogReg β=1.0: CV Accuracy= [0.7010] + [0.0105]\n",
      "L2 LogReg β=2.0: CV Accuracy= [0.6997] + [0.0105]\n",
      "L2 LogReg β=3.0: CV Accuracy= [0.6991] + [0.0112]\n",
      "L2 LogReg β=4.0: CV Accuracy= [0.6980] + [0.0128]\n",
      "L2 LogReg β=5.0: CV Accuracy= [0.6978] + [0.0128]\n",
      "L2 LogReg β=6.0: CV Accuracy= [0.6983] + [0.0133]\n",
      "L2 LogReg β=7.0: CV Accuracy= [0.6980] + [0.0135]\n",
      "L2 LogReg β=8.0: CV Accuracy= [0.6980] + [0.0135]\n",
      "L2 LogReg β=9.0: CV Accuracy= [0.6983] + [0.0135]\n",
      "L2 LogReg β=10.0: CV Accuracy= [0.6980] + [0.0135]\n",
      "L1 LogReg β=0.1: CV Accuracy= [0.7109] + [0.0070]\n",
      "L1 LogReg β=0.2: CV Accuracy= [0.7111] + [0.0084]\n",
      "L1 LogReg β=0.3: CV Accuracy= [0.7104] + [0.0101]\n",
      "L1 LogReg β=0.4: CV Accuracy= [0.7086] + [0.0090]\n",
      "L1 LogReg β=0.5: CV Accuracy= [0.7077] + [0.0106]\n",
      "L1 LogReg β=0.6: CV Accuracy= [0.7050] + [0.0110]\n",
      "L1 LogReg β=0.7: CV Accuracy= [0.7046] + [0.0115]\n",
      "L1 LogReg β=0.8: CV Accuracy= [0.7054] + [0.0118]\n",
      "L1 LogReg β=0.9: CV Accuracy= [0.7056] + [0.0131]\n",
      "L1 LogReg β=1.0: CV Accuracy= [0.7062] + [0.0120]\n",
      "L1 LogReg β=2.0: CV Accuracy= [0.7018] + [0.0125]\n",
      "L1 LogReg β=3.0: CV Accuracy= [0.6997] + [0.0117]\n",
      "L1 LogReg β=4.0: CV Accuracy= [0.6997] + [0.0125]\n",
      "L1 LogReg β=5.0: CV Accuracy= [0.6987] + [0.0130]\n",
      "L1 LogReg β=6.0: CV Accuracy= [0.6978] + [0.0135]\n",
      "L1 LogReg β=7.0: CV Accuracy= [0.6983] + [0.0133]\n",
      "L1 LogReg β=8.0: CV Accuracy= [0.6985] + [0.0134]\n",
      "L1 LogReg β=9.0: CV Accuracy= [0.6991] + [0.0133]\n",
      "L1 LogReg β=10.0: CV Accuracy= [0.6991] + [0.0133]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.73      0.74      0.73       625\n",
      "       True       0.71      0.70      0.70       565\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1190\n",
      "\n",
      "[[462 163]\n",
      " [172 393]]\n",
      "\n",
      "L1 LogReg β=0.2: Accuracy= 0.7185\n"
     ]
    }
   ],
   "source": [
    "# 2. Logistic Regression\n",
    "logreg, logreg_cv_acc = LogReg_grid_search(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:22:24.305121Z",
     "start_time": "2019-02-14T01:22:24.293354Z"
    }
   },
   "outputs": [],
   "source": [
    "def SVM(data, beta, mode='cv', n_folds=5, seed=seed):\n",
    "    train_x, test_x, train_y, test_y = data\n",
    "\n",
    "    from sklearn.svm import SVC\n",
    "    svm = SVC(C=beta,\n",
    "              kernel='rbf',\n",
    "              random_state=seed)\n",
    "\n",
    "    if mode == 'cv':\n",
    "        acc_list = cross_val_score(svm, all_x(data), all_y(data),\n",
    "                                   cv=n_folds,\n",
    "                                   n_jobs=-1)\n",
    "        return None, acc_list\n",
    "    else:\n",
    "        svm = svm.fit(train_x, train_y)\n",
    "        test_y_hat = svm.predict(test_x)\n",
    "        acc = accuracy_score(test_y_hat, test_y)\n",
    "\n",
    "        print(classification_report(test_y, test_y_hat))\n",
    "        print(confusion_matrix(test_y, test_y_hat))\n",
    "        return svm, acc\n",
    "\n",
    "\n",
    "beta_grid = np.concatenate((np.linspace(.1, .9, 9), np.linspace(1, 10, 10)))\n",
    "\n",
    "\n",
    "def SVM_grid_search(data, beta_grid=beta_grid):\n",
    "    beta_opt, acc_opt = 0, 0\n",
    "    for beta in beta_grid:\n",
    "        _, acc_list = SVM(data,\n",
    "                          beta=beta,\n",
    "                          mode='cv')\n",
    "        acc_mean, acc_std = acc_list.mean(), acc_list.std()\n",
    "        print(\n",
    "            f'SVM β={beta:.1f}: CV Accuracy= [{acc_mean:.4f}] + [{acc_std:.4f}]')\n",
    "        if acc_mean > acc_opt:\n",
    "            beta_opt, acc_opt = beta, acc_mean\n",
    "\n",
    "    svm, acc = SVM(data,\n",
    "                   beta=beta_opt,\n",
    "                   mode='train')\n",
    "    print(f'\\nSVM β={beta_opt:.1f}: Accuracy= {acc:.4f}')\n",
    "    return svm, acc_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:24:10.160182Z",
     "start_time": "2019-02-14T01:22:24.306644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM β=0.1: CV Accuracy= [0.6247] + [0.0062]\n",
      "SVM β=0.2: CV Accuracy= [0.6531] + [0.0041]\n",
      "SVM β=0.3: CV Accuracy= [0.6722] + [0.0042]\n",
      "SVM β=0.4: CV Accuracy= [0.6861] + [0.0045]\n",
      "SVM β=0.5: CV Accuracy= [0.6936] + [0.0073]\n",
      "SVM β=0.6: CV Accuracy= [0.6999] + [0.0075]\n",
      "SVM β=0.7: CV Accuracy= [0.7041] + [0.0070]\n",
      "SVM β=0.8: CV Accuracy= [0.7039] + [0.0077]\n",
      "SVM β=0.9: CV Accuracy= [0.7094] + [0.0077]\n",
      "SVM β=1.0: CV Accuracy= [0.7128] + [0.0048]\n",
      "SVM β=2.0: CV Accuracy= [0.7226] + [0.0089]\n",
      "SVM β=3.0: CV Accuracy= [0.7262] + [0.0110]\n",
      "SVM β=4.0: CV Accuracy= [0.7212] + [0.0129]\n",
      "SVM β=5.0: CV Accuracy= [0.7201] + [0.0115]\n",
      "SVM β=6.0: CV Accuracy= [0.7188] + [0.0118]\n",
      "SVM β=7.0: CV Accuracy= [0.7153] + [0.0122]\n",
      "SVM β=8.0: CV Accuracy= [0.7127] + [0.0128]\n",
      "SVM β=9.0: CV Accuracy= [0.7128] + [0.0119]\n",
      "SVM β=10.0: CV Accuracy= [0.7121] + [0.0125]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.74      0.76      0.75       625\n",
      "       True       0.72      0.70      0.71       565\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1190\n",
      "\n",
      "[[473 152]\n",
      " [167 398]]\n",
      "\n",
      "SVM β=3.0: Accuracy= 0.7319\n"
     ]
    }
   ],
   "source": [
    "# 3. SVM\n",
    "svm, svm_cv_acc = SVM_grid_search(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:24:10.174487Z",
     "start_time": "2019-02-14T01:24:10.162952Z"
    }
   },
   "outputs": [],
   "source": [
    "def RandomForest(data, depth, mode='oob', seed=seed):\n",
    "    train_x, test_x, train_y, test_y = data\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    forest = RandomForestClassifier(n_estimators=1000,\n",
    "                                    max_depth=depth,\n",
    "                                    oob_score=True,\n",
    "                                    n_jobs=-1,\n",
    "                                    random_state=seed)\n",
    "    forest = forest.fit(train_x, train_y)\n",
    "    test_y_hat = forest.predict(test_x)\n",
    "\n",
    "    if mode == 'oob':\n",
    "        acc_oob = forest.oob_score_\n",
    "        return forest, acc_oob\n",
    "    else:\n",
    "        acc = accuracy_score(test_y_hat, test_y)\n",
    "        print(classification_report(test_y, test_y_hat))\n",
    "        print(confusion_matrix(test_y, test_y_hat))\n",
    "        return forest, acc\n",
    "\n",
    "\n",
    "beta_grid = np.concatenate((np.linspace(.1, .9, 9), np.linspace(1, 10, 10)))\n",
    "\n",
    "\n",
    "def RandomForest_grid_search(data, depth_grid=range(2, 11)):\n",
    "    depth_opt, acc_opt = 0, 0\n",
    "    for depth in depth_grid:\n",
    "        _, acc_oob = RandomForest(data,\n",
    "                                  depth=depth,\n",
    "                                  mode='oob')\n",
    "        print(f'RandomForest depth={depth}: OOB Accuracy= [{acc_oob:.4f}]')\n",
    "        if acc_oob > acc_opt:\n",
    "            depth_opt, acc_opt = depth, acc_oob\n",
    "\n",
    "    forest, acc = RandomForest(data,\n",
    "                               depth=depth_opt,\n",
    "                               mode='train')\n",
    "    print(f'\\nRandomForest depth={depth_opt}: Accuracy= {acc:.4f}')\n",
    "    return forest, acc_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:24:42.010235Z",
     "start_time": "2019-02-14T01:24:10.176106Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/s1895566/miniconda/base/envs/venv/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest depth=2: OOB Accuracy= [0.8148]\n",
      "RandomForest depth=3: OOB Accuracy= [0.8254]\n",
      "RandomForest depth=4: OOB Accuracy= [0.8322]\n",
      "RandomForest depth=5: OOB Accuracy= [0.8431]\n",
      "RandomForest depth=6: OOB Accuracy= [0.8484]\n",
      "RandomForest depth=7: OOB Accuracy= [0.8476]\n",
      "RandomForest depth=8: OOB Accuracy= [0.8493]\n",
      "RandomForest depth=9: OOB Accuracy= [0.8509]\n",
      "RandomForest depth=10: OOB Accuracy= [0.8523]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.85      0.88      0.86       625\n",
      "       True       0.86      0.82      0.84       565\n",
      "\n",
      "avg / total       0.85      0.85      0.85      1190\n",
      "\n",
      "[[551  74]\n",
      " [101 464]]\n",
      "\n",
      "RandomForest depth=10: Accuracy= 0.8529\n"
     ]
    }
   ],
   "source": [
    "# 4. Random Forest\n",
    "forest, forest_oob_acc = RandomForest_grid_search(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T00:24:22.792514Z",
     "start_time": "2019-02-14T00:24:22.790238Z"
    }
   },
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:24:42.020598Z",
     "start_time": "2019-02-14T01:24:42.012775Z"
    }
   },
   "outputs": [],
   "source": [
    "def Bagging(data, mode='oob', seed=seed):\n",
    "    train_x, test_x, train_y, test_y = data\n",
    "\n",
    "    from sklearn.ensemble import BaggingClassifier\n",
    "    bag = BaggingClassifier(n_estimators=1000,\n",
    "                            oob_score=True,\n",
    "                            n_jobs=-1,\n",
    "                            random_state=seed)\n",
    "    bag = bag.fit(train_x, train_y)\n",
    "    test_y_hat = bag.predict(test_x)\n",
    "\n",
    "    if mode == 'oob':\n",
    "        acc_oob = bag.oob_score_\n",
    "        print(f'Bagging: OOB Accuracy= [{acc_oob:.4f}]')\n",
    "        print(classification_report(test_y, test_y_hat))\n",
    "        print(confusion_matrix(test_y, test_y_hat))\n",
    "        return bag, acc_oob\n",
    "    else:\n",
    "        acc = accuracy_score(test_y_hat, test_y)\n",
    "        print(f'Bagging: Accuracy= [{acc:.4f}]')\n",
    "        print(classification_report(test_y, test_y_hat))\n",
    "        print(confusion_matrix(test_y, test_y_hat))\n",
    "        return bag, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:25:00.946758Z",
     "start_time": "2019-02-14T01:24:42.022495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging: OOB Accuracy= [0.8501]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.84      0.89      0.87       625\n",
      "       True       0.87      0.81      0.84       565\n",
      "\n",
      "avg / total       0.86      0.86      0.86      1190\n",
      "\n",
      "[[559  66]\n",
      " [106 459]]\n"
     ]
    }
   ],
   "source": [
    "# 5. Bagging\n",
    "bag, bag_oob_acc = Bagging(all_data,\n",
    "                           mode='oob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:25:00.955252Z",
     "start_time": "2019-02-14T01:25:00.949286Z"
    }
   },
   "outputs": [],
   "source": [
    "def DecisionTree(data, depth=None, seed=seed):\n",
    "    train_x, test_x, train_y, test_y = data\n",
    "\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    tree = DecisionTreeClassifier(max_depth=depth,\n",
    "                                  random_state=seed)\n",
    "    tree = tree.fit(train_x, train_y)\n",
    "    test_y_hat = tree.predict(test_x)\n",
    "\n",
    "    acc = accuracy_score(test_y_hat, test_y)\n",
    "    print(classification_report(test_y, test_y_hat))\n",
    "    print(confusion_matrix(test_y, test_y_hat))\n",
    "    return tree, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:25:01.835057Z",
     "start_time": "2019-02-14T01:25:00.957043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.81      0.77      0.79       625\n",
      "       True       0.76      0.80      0.78       565\n",
      "\n",
      "avg / total       0.79      0.78      0.78      1190\n",
      "\n",
      "[[481 144]\n",
      " [113 452]]\n"
     ]
    }
   ],
   "source": [
    "# 6. Decision Tree\n",
    "tree, tree_acc = DecisionTree(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:25:01.844763Z",
     "start_time": "2019-02-14T01:25:01.836918Z"
    }
   },
   "outputs": [],
   "source": [
    "def ExtraTrees(data, depth=None, mode='oob', seed=seed):\n",
    "    train_x, test_x, train_y, test_y = data\n",
    "\n",
    "    from sklearn.ensemble import ExtraTreesClassifier\n",
    "    extra = ExtraTreesClassifier(n_estimators=1000,\n",
    "                                 max_depth=depth,\n",
    "                                 oob_score=mode == 'oob',\n",
    "                                 bootstrap=mode == 'oob',\n",
    "                                 n_jobs=-1,\n",
    "                                 random_state=seed)\n",
    "    extra = extra.fit(train_x, train_y)\n",
    "    test_y_hat = extra.predict(test_x)\n",
    "\n",
    "    if mode == 'oob':\n",
    "        acc_oob = extra.oob_score_\n",
    "        print(f'ExtraTrees: OOB Accuracy= [{acc_oob:.4f}]')\n",
    "        print(classification_report(test_y, test_y_hat))\n",
    "        print(confusion_matrix(test_y, test_y_hat))\n",
    "        return extra, acc_oob\n",
    "    else:\n",
    "        acc = accuracy_score(test_y_hat, test_y)\n",
    "        print(f'ExtraTrees: Accuracy= [{acc:.4f}]')\n",
    "        print(classification_report(test_y, test_y_hat))\n",
    "        print(confusion_matrix(test_y, test_y_hat))\n",
    "        return extra, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:25:04.520149Z",
     "start_time": "2019-02-14T01:25:01.846414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees: Accuracy= [0.7387]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.77      0.72      0.74       625\n",
      "       True       0.71      0.76      0.73       565\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1190\n",
      "\n",
      "[[449 176]\n",
      " [135 430]]\n"
     ]
    }
   ],
   "source": [
    "# 7. Extra Trees\n",
    "extra, extra_oob_acc = ExtraTrees(all_data,\n",
    "                                  mode='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:25:04.527570Z",
     "start_time": "2019-02-14T01:25:04.522196Z"
    }
   },
   "outputs": [],
   "source": [
    "def GradB(data, seed=seed):\n",
    "    train_x, test_x, train_y, test_y = data\n",
    "\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    gradb = GradientBoostingClassifier(n_estimators=1000,\n",
    "                                       random_state=seed)\n",
    "    gradb = gradb.fit(train_x, train_y)\n",
    "    test_y_hat = gradb.predict(test_x)\n",
    "\n",
    "    acc = accuracy_score(test_y_hat, test_y)\n",
    "    print(f'Gradient Boosting: Accuracy= [{acc:.4f}]')\n",
    "    print(classification_report(test_y, test_y_hat))\n",
    "    print(confusion_matrix(test_y, test_y_hat))\n",
    "    return gradb, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:25:54.086744Z",
     "start_time": "2019-02-14T01:25:04.529139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting: Accuracy= [0.8513]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.85      0.87      0.86       625\n",
      "       True       0.85      0.83      0.84       565\n",
      "\n",
      "avg / total       0.85      0.85      0.85      1190\n",
      "\n",
      "[[545  80]\n",
      " [ 97 468]]\n"
     ]
    }
   ],
   "source": [
    "# 8. Gradient Boosting\n",
    "gradb, gradb_acc = GradB(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:25:54.094920Z",
     "start_time": "2019-02-14T01:25:54.089087Z"
    }
   },
   "outputs": [],
   "source": [
    "def AdaB(data, seed=seed):\n",
    "    train_x, test_x, train_y, test_y = data\n",
    "\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    adab = AdaBoostClassifier(n_estimators=1000,\n",
    "                              random_state=seed)\n",
    "    adab = adab.fit(train_x, train_y)\n",
    "    test_y_hat = adab.predict(test_x)\n",
    "\n",
    "    acc = accuracy_score(test_y_hat, test_y)\n",
    "    print(f'AdaBoost: Accuracy= [{acc:.4f}]')\n",
    "    print(classification_report(test_y, test_y_hat))\n",
    "    print(confusion_matrix(test_y, test_y_hat))\n",
    "    return adab, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:27:17.169641Z",
     "start_time": "2019-02-14T01:25:54.096744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost: Accuracy= [0.8210]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.82      0.85      0.83       625\n",
      "       True       0.82      0.79      0.81       565\n",
      "\n",
      "avg / total       0.82      0.82      0.82      1190\n",
      "\n",
      "[[529  96]\n",
      " [117 448]]\n"
     ]
    }
   ],
   "source": [
    "# 9. AdaBoost\n",
    "adab, adab_acc = AdaB(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:27:17.177402Z",
     "start_time": "2019-02-14T01:27:17.171886Z"
    }
   },
   "outputs": [],
   "source": [
    "def XGB(data, seed=seed):\n",
    "    train_x, test_x, train_y, test_y = data\n",
    "\n",
    "    from xgboost import XGBClassifier\n",
    "    xgb = XGBClassifier(random_state=seed)\n",
    "    xgb = xgb.fit(train_x, train_y)\n",
    "    test_y_hat = xgb.predict(test_x)\n",
    "\n",
    "    acc = accuracy_score(test_y_hat, test_y)\n",
    "    print(f'XGBoosting: Accuracy= [{acc:.4f}]')\n",
    "    print(classification_report(test_y, test_y_hat))\n",
    "    print(confusion_matrix(test_y, test_y_hat))\n",
    "    return xgb, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:27:20.659902Z",
     "start_time": "2019-02-14T01:27:17.179212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoosting: Accuracy= [0.8580]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.85      0.89      0.87       625\n",
      "       True       0.87      0.82      0.85       565\n",
      "\n",
      "avg / total       0.86      0.86      0.86      1190\n",
      "\n",
      "[[558  67]\n",
      " [102 463]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/s1895566/miniconda/base/envs/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# 10. XGBoost\n",
    "xgb, xgb_acc = XGB(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:27:20.667647Z",
     "start_time": "2019-02-14T01:27:20.661793Z"
    }
   },
   "outputs": [],
   "source": [
    "def NBayes(data, priors=None):\n",
    "    train_x, test_x, train_y, test_y = data\n",
    "\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    bayes = GaussianNB(priors=priors)\n",
    "    bayes = bayes.fit(train_x, train_y)\n",
    "    test_y_hat = bayes.predict(test_x)\n",
    "\n",
    "    acc = accuracy_score(test_y_hat, test_y)\n",
    "    print(f'Naïve Bayes: Accuracy= [{acc:.4f}]')\n",
    "    print(classification_report(test_y, test_y_hat))\n",
    "    print(confusion_matrix(test_y, test_y_hat))\n",
    "    return bayes, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:27:20.691726Z",
     "start_time": "2019-02-14T01:27:20.669410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes: Accuracy= [0.5420]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.54      0.96      0.69       625\n",
      "       True       0.64      0.08      0.14       565\n",
      "\n",
      "avg / total       0.58      0.54      0.43      1190\n",
      "\n",
      "[[599  26]\n",
      " [519  46]]\n"
     ]
    }
   ],
   "source": [
    "# 11. Naïve Bayes\n",
    "bayes, bayes_acc = NBayes(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:27:20.699081Z",
     "start_time": "2019-02-14T01:27:20.693573Z"
    }
   },
   "outputs": [],
   "source": [
    "def GP(data, seed=seed):\n",
    "    train_x, test_x, train_y, test_y = data\n",
    "\n",
    "    from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "    gp = GaussianProcessClassifier(n_jobs=-1,\n",
    "                                   random_state=seed)\n",
    "    gp = gp.fit(train_x, train_y)\n",
    "    test_y_hat = gp.predict(test_x)\n",
    "\n",
    "    acc = accuracy_score(test_y_hat, test_y)\n",
    "    print(f'Gaussian Process: Accuracy= [{acc:.4f}]')\n",
    "    print(classification_report(test_y, test_y_hat))\n",
    "    print(confusion_matrix(test_y, test_y_hat))\n",
    "    return gp, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:27:46.218648Z",
     "start_time": "2019-02-14T01:27:20.700863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Process: Accuracy= [0.6176]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.64      0.62      0.63       625\n",
      "       True       0.59      0.62      0.60       565\n",
      "\n",
      "avg / total       0.62      0.62      0.62      1190\n",
      "\n",
      "[[387 238]\n",
      " [217 348]]\n"
     ]
    }
   ],
   "source": [
    "# 12. Gaussian Process\n",
    "gp, gp_acc = GP(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:27:46.227146Z",
     "start_time": "2019-02-14T01:27:46.220678Z"
    }
   },
   "outputs": [],
   "source": [
    "def Voting(data, models, model_name, weights='None', how_to_vote='hard'):\n",
    "    train_x, test_x, train_y, test_y = data\n",
    "    model_zip = list(zip(model_name, models))\n",
    "\n",
    "    from sklearn.ensemble import VotingClassifier\n",
    "    vote = VotingClassifier(estimators=model_zip,\n",
    "                            voting=how_to_vote,\n",
    "                            weights=weights,\n",
    "                            n_jobs=-1)\n",
    "    vote = vote.fit(train_x, train_y)\n",
    "    test_y_hat = vote.predict(test_x)\n",
    "\n",
    "    acc = accuracy_score(test_y_hat, test_y)\n",
    "    print(f'{how_to_vote.capitalize()} voting: Accuracy= [{acc:.4f}]')\n",
    "    print(classification_report(test_y, test_y_hat))\n",
    "    print(confusion_matrix(test_y, test_y_hat))\n",
    "    return vote, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:27:46.254865Z",
     "start_time": "2019-02-14T01:27:46.228939Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoosting</th>\n",
       "      <td>0.857983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.852340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.851261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.850098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoosting</th>\n",
       "      <td>0.821008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.784034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extra Trees</th>\n",
       "      <td>0.738655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.726202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.711072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.624920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Process</th>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes</th>\n",
       "      <td>0.542017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy\n",
       "Model                        \n",
       "XGBoosting           0.857983\n",
       "Random Forest        0.852340\n",
       "Gradient Boosting    0.851261\n",
       "Bagging              0.850098\n",
       "AdaBoosting          0.821008\n",
       "Decision Tree        0.784034\n",
       "Extra Trees          0.738655\n",
       "SVM                  0.726202\n",
       "Logistic Regression  0.711072\n",
       "KNN                  0.624920\n",
       "Gaussian Process     0.617647\n",
       "Naïve Bayes          0.542017"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [knn, logreg, svm, forest, bag,\n",
    "          tree, extra, gradb, adab, xgb, bayes, gp]\n",
    "\n",
    "model_name = ['KNN', 'Logistic Regression', 'SVM', 'Random Forest', 'Bagging', 'Decision Tree',\n",
    "              'Extra Trees', 'Gradient Boosting', 'AdaBoosting', 'XGBoosting', 'Naïve Bayes', 'Gaussian Process']\n",
    "\n",
    "model_acc = [knn_cv_acc, logreg_cv_acc, svm_cv_acc, forest_oob_acc, bag_oob_acc,\n",
    "             tree_acc, extra_oob_acc, gradb_acc, adab_acc, xgb_acc, bayes_acc, gp_acc]\n",
    "\n",
    "model_summary = pd.DataFrame({'Model': model_name,\n",
    "                              'Accuracy': model_acc}).set_index('Model').sort_values('Accuracy',\n",
    "                                                                                     ascending=False)\n",
    "model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:38:14.480878Z",
     "start_time": "2019-02-14T01:27:46.256678Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/s1895566/miniconda/base/envs/venv/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/scratch/s1895566/miniconda/base/envs/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard voting: Accuracy= [0.8571]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.84      0.90      0.87       625\n",
      "       True       0.88      0.81      0.84       565\n",
      "\n",
      "avg / total       0.86      0.86      0.86      1190\n",
      "\n",
      "[[560  65]\n",
      " [105 460]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/s1895566/miniconda/base/envs/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# ∞. Voting\n",
    "vote, vote_acc = Voting(all_data, models, model_name, weights=model_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:38:14.490339Z",
     "start_time": "2019-02-14T01:38:14.482928Z"
    }
   },
   "outputs": [],
   "source": [
    "def Stacking(data, models, seed=seed):\n",
    "    train_x, test_x, train_y, test_y = data\n",
    "\n",
    "    from vecstack import stacking\n",
    "    train_S, test_S = stacking(models,\n",
    "                               train_x, train_y, test_x,\n",
    "                               regression=False,\n",
    "                               mode='oof_pred_bag',\n",
    "                               needs_proba=False,\n",
    "                               save_dir=None,\n",
    "                               metric=accuracy_score,\n",
    "                               n_folds=5,\n",
    "                               stratified=False,\n",
    "                               shuffle=False,\n",
    "                               random_state=seed,\n",
    "                               verbose=2)\n",
    "    train_S, test_S, _ = standardize(train_S, test_S)\n",
    "    return train_S, test_S\n",
    "\n",
    "def Two_Level_Stacking(data, models, seed=seed):\n",
    "    train_x, test_x, train_y, test_y = data\n",
    "    \n",
    "    train_S, test_S = Stacking(data, models, seed=seed)\n",
    "    S_data = [train_S, test_S, train_y, test_y]\n",
    "    second_lev_classifier, stacking_acc = RandomForest_grid_search(S_data)\n",
    "    return second_lev_classifier, stacking_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:51:29.297569Z",
     "start_time": "2019-02-14T01:38:14.491863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [12]\n",
      "\n",
      "model  0:     [KNeighborsClassifier]\n",
      "    fold  0:  [0.62605042]\n",
      "    fold  1:  [0.59243697]\n",
      "    fold  2:  [0.63725490]\n",
      "    fold  3:  [0.62745098]\n",
      "    fold  4:  [0.62131837]\n",
      "    ----\n",
      "    MEAN:     [0.62090233] + [0.01514757]\n",
      "    FULL:     [0.62090221]\n",
      "\n",
      "model  1:     [LogisticRegression]\n",
      "    fold  0:  [0.72829132]\n",
      "    fold  1:  [0.70868347]\n",
      "    fold  2:  [0.71428571]\n",
      "    fold  3:  [0.72549020]\n",
      "    fold  4:  [0.71248247]\n",
      "    ----\n",
      "    MEAN:     [0.71784663] + [0.00765419]\n",
      "    FULL:     [0.71784814]\n",
      "\n",
      "model  2:     [SVC]\n",
      "    fold  0:  [0.72128852]\n",
      "    fold  1:  [0.69607843]\n",
      "    fold  2:  [0.70588235]\n",
      "    fold  3:  [0.72549020]\n",
      "    fold  4:  [0.71528752]\n",
      "    ----\n",
      "    MEAN:     [0.71280540] + [0.01064658]\n",
      "    FULL:     [0.71280471]\n",
      "\n",
      "model  3:     [RandomForestClassifier]\n",
      "    fold  0:  [0.84173669]\n",
      "    fold  1:  [0.87535014]\n",
      "    fold  2:  [0.85574230]\n",
      "    fold  3:  [0.84593838]\n",
      "    fold  4:  [0.82328191]\n",
      "    ----\n",
      "    MEAN:     [0.84840988] + [0.01709735]\n",
      "    FULL:     [0.84841692]\n",
      "\n",
      "model  4:     [BaggingClassifier]\n",
      "    fold  0:  [0.85294118]\n",
      "    fold  1:  [0.88375350]\n",
      "    fold  2:  [0.85014006]\n",
      "    fold  3:  [0.84873950]\n",
      "    fold  4:  [0.82047686]\n",
      "    ----\n",
      "    MEAN:     [0.85121022] + [0.02006913]\n",
      "    FULL:     [0.85121883]\n",
      "\n",
      "model  5:     [DecisionTreeClassifier]\n",
      "    fold  0:  [0.78571429]\n",
      "    fold  1:  [0.74369748]\n",
      "    fold  2:  [0.76610644]\n",
      "    fold  3:  [0.78151261]\n",
      "    fold  4:  [0.75035063]\n",
      "    ----\n",
      "    MEAN:     [0.76547629] + [0.01655439]\n",
      "    FULL:     [0.76548053]\n",
      "\n",
      "model  6:     [ExtraTreesClassifier]\n",
      "    fold  0:  [0.73109244]\n",
      "    fold  1:  [0.72408964]\n",
      "    fold  2:  [0.72969188]\n",
      "    fold  3:  [0.72128852]\n",
      "    fold  4:  [0.73492286]\n",
      "    ----\n",
      "    MEAN:     [0.72821707] + [0.00490818]\n",
      "    FULL:     [0.72821519]\n",
      "\n",
      "model  7:     [GradientBoostingClassifier]\n",
      "    fold  0:  [0.84873950]\n",
      "    fold  1:  [0.86134454]\n",
      "    fold  2:  [0.83893557]\n",
      "    fold  3:  [0.83613445]\n",
      "    fold  4:  [0.82748948]\n",
      "    ----\n",
      "    MEAN:     [0.84252871] + [0.01159814]\n",
      "    FULL:     [0.84253292]\n",
      "\n",
      "model  8:     [AdaBoostClassifier]\n",
      "    fold  0:  [0.81652661]\n",
      "    fold  1:  [0.84033613]\n",
      "    fold  2:  [0.80532213]\n",
      "    fold  3:  [0.82212885]\n",
      "    fold  4:  [0.79803647]\n",
      "    ----\n",
      "    MEAN:     [0.81647004] + [0.01459924]\n",
      "    FULL:     [0.81647520]\n",
      "\n",
      "model  9:     [XGBClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/s1895566/miniconda/base/envs/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/scratch/s1895566/miniconda/base/envs/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  0:  [0.86274510]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/s1895566/miniconda/base/envs/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/scratch/s1895566/miniconda/base/envs/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  1:  [0.86974790]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/s1895566/miniconda/base/envs/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/scratch/s1895566/miniconda/base/envs/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  2:  [0.85434174]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/s1895566/miniconda/base/envs/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/scratch/s1895566/miniconda/base/envs/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  3:  [0.85294118]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/s1895566/miniconda/base/envs/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/scratch/s1895566/miniconda/base/envs/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  4:  [0.83029453]\n",
      "    ----\n",
      "    MEAN:     [0.85401409] + [0.01332411]\n",
      "    FULL:     [0.85402073]\n",
      "\n",
      "model 10:     [GaussianNB]\n",
      "    fold  0:  [0.53081232]\n",
      "    fold  1:  [0.55462185]\n",
      "    fold  2:  [0.52801120]\n",
      "    fold  3:  [0.53501401]\n",
      "    fold  4:  [0.53997195]\n",
      "    ----\n",
      "    MEAN:     [0.53768627] + [0.00938123]\n",
      "    FULL:     [0.53768563]\n",
      "\n",
      "model 11:     [GaussianProcessClassifier]\n",
      "    fold  0:  [0.61624650]\n",
      "    fold  1:  [0.57983193]\n",
      "    fold  2:  [0.61904762]\n",
      "    fold  3:  [0.60644258]\n",
      "    fold  4:  [0.62131837]\n",
      "    ----\n",
      "    MEAN:     [0.60857740] + [0.01524226]\n",
      "    FULL:     [0.60857383]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/s1895566/miniconda/base/envs/venv/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/scratch/s1895566/miniconda/base/envs/venv/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/scratch/s1895566/miniconda/base/envs/venv/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest depth=2: OOB Accuracy= [0.8532]\n",
      "RandomForest depth=3: OOB Accuracy= [0.8537]\n",
      "RandomForest depth=4: OOB Accuracy= [0.8537]\n",
      "RandomForest depth=5: OOB Accuracy= [0.8540]\n",
      "RandomForest depth=6: OOB Accuracy= [0.8526]\n",
      "RandomForest depth=7: OOB Accuracy= [0.8532]\n",
      "RandomForest depth=8: OOB Accuracy= [0.8535]\n",
      "RandomForest depth=9: OOB Accuracy= [0.8523]\n",
      "RandomForest depth=10: OOB Accuracy= [0.8476]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.84      0.90      0.87       625\n",
      "       True       0.88      0.81      0.84       565\n",
      "\n",
      "avg / total       0.86      0.86      0.86      1190\n",
      "\n",
      "[[560  65]\n",
      " [105 460]]\n",
      "\n",
      "RandomForest depth=5: Accuracy= 0.8571\n"
     ]
    }
   ],
   "source": [
    "# Stacking\n",
    "_, stacking_acc = Two_Level_Stacking(all_data, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Conversion (for ssh Burn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T01:51:29.302078Z",
     "start_time": "2019-02-14T01:51:29.299717Z"
    }
   },
   "outputs": [],
   "source": [
    "#!jupyter nbconvert --to script neural-net.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.85,
   "position": {
    "height": "40px",
    "left": "1170px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
